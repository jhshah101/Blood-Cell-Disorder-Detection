# ğŸ§¬ Software Front and Back End White Blood Cells Classification

An AI-powered system for **classifying white blood cells** ğŸ©¸  

- âš¡ **PyTorch** â€“ Deep learning backbone  
- ğŸŒ **FastAPI** â€“ Backend API for predictions  
- ğŸ¨ **Lovable** â€“ Frontend UI  
- ğŸ“Š **Dataset** â€“ From Kaggle  

---

## ğŸš€ Features
- ğŸ” Detects and classifies multiple WBC types  
- ğŸ“ˆ Handles **class imbalance** with dynamic weights  
- ğŸ›‘ Early stopping with best-model saving  
- ğŸ–¼ï¸ Confusion matrix & training curves  
- ğŸŒ Full-stack integration (Frontend + Backend)  
- â˜ï¸ **Reusable Notebook (`Software_code.ipynb`)** for **Google Colab**  

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/white-blood-cells-classification.git
cd white-blood-cells-classification
```

### 2ï¸âƒ£ Run Backend (Optional â€“ for API deployment)
```bash
cd backend
pip install -r requirements.txt

# Run the backend
python -m uvicorn App.backend:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ“’ Reusable Code on Google Colab

If you donâ€™t want to set up the backend/frontend and just need the **core model training and evaluation**, use the notebook:

â¡ï¸ Open (Software_code.ipynb) in **Google Colab**.  

Steps inside Colab:
1. Upload the dataset (or mount Google Drive).  
2. Install required libraries (PyTorch, torchvision, scikit-learn, matplotlib).  
3. Run cells step by step:
   - **Data loading & preprocessing**  
   - **Model definition (CNN + Transformer hybrid)**  
   - **Weighted loss for imbalance**  
   - **Training with early stopping**  
   - **Evaluation: confusion matrix, accuracy, per-class report**  
4. Save trained model (`best_model.pth`) for later use.  

This way, the notebook works as a **standalone, reusable training pipeline** without needing backend or frontend setup.  

---

## ğŸ§‘â€ğŸ’» Contributors
ğŸ‘¨â€ğŸ”¬ [jamal] â€“ ML Engineer  
ğŸ¨ Lovable â€“ Frontend  
âš¡ FastAPI â€“ Backend  
